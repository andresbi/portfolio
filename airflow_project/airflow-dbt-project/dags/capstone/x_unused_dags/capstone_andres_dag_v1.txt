import os
import sys
from datetime import datetime, timedelta
from cosmos import DbtTask, ProjectConfig, ProfileConfig, RenderConfig
from airflow.operators.empty import EmptyOperator
from airflow.decorators import dag
from dotenv import load_dotenv
# from airflow import DAG
from airflow.operators.python import PythonOperator

from dags.capstone.python_scripts.load_polygon_into_snowflake import load_polygon_main 
from dags.capstone.python_scripts.load_treasury_into_snowflake import load_treasury_main 


#Set up dbt 
dbt_env_path = os.path.join(os.environ['AIRFLOW_HOME'], 'dbt_capstone_andres', 'dbt.env')
load_dotenv(dbt_env_path)

# Retrieve environment variables
airflow_home = os.getenv('AIRFLOW_HOME')
PATH_TO_DBT_PROJECT = f'{airflow_home}/dags/capstone/dbt_capstone_andres'
PATH_TO_DBT_PROFILES = f'{airflow_home}/dags/capstone/dbt_capstone_andres/profiles.yml'

profile_config = ProfileConfig(
    profile_name="dbt_capstone_andres",
    target_name="dev",
    profiles_yml_filepath=PATH_TO_DBT_PROFILES,
)

default_dbt_args = {
  "owner": "Andres",
  "retries": 0,
  "execution_timeout": timedelta(hours=1),
}


# Extract and Load arguments
default_args = {
    'owner': 'andres',
    'depends_on_past': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
    'email_on_failure': False,
    "start_date": datetime(2024, 11, 1),
    'email_on_retry': False,
    'execution_timeout': timedelta(hours=1),
    'wait_for_downstream':True
}

# Define the DAG.
@dag(
    default_args=default_args,
    description='DAG to load Polygon data into Snowflake using Snowpark',
    schedule_interval="0 1 * * *",
    catchup=True,
    template_searchpath='dags/capstone/python_scripts',
    max_active_runs=3,
)   

def elt_dag():
    load_polygon_data_task = PythonOperator(
    task_id='load_polygon_data_task',
    python_callable=load_polygon_main,
    depends_on_past=True,
    op_kwargs={
        "date_to_ingest": '{{ yesterday_ds }}'
    },
    )

    load_treasury_data_task = PythonOperator(    
    task_id='load_treasury_data_task',
    python_callable=load_treasury_main,
    depends_on_past=True,
    op_kwargs={
        "date_to_ingest": '{{ yesterday_ds }}'
    },
    )


    dbt_build_weekly_metrics_task = DbtTask(
    task_id="dbt_build_weekly_metrics_task",
    project_config=ProjectConfig(
    project_root=PATH_TO_DBT_PROJECT,
    ),
    profile_config=profile_config,
    select=["+weekly_metrics"],  # Specify the selection criteria
    retries=0,
    )

#     dbt_build_weekly_metrics_task = DbtDag(
#     task_id="dbt_build_weekly_metrics_task",
#     project_config=ProjectConfig(PATH_TO_DBT_PROJECT),
#     profile_config=profile_config,
#     render_config=RenderConfig(
#         select=["+weekly_metrics"],
#     ),
#     start_date=datetime(2024, 5, 9),
#     # schedule='@once',
#     schedule_interval="0 2 * * *",
#     catchup=False,
#     default_args=default_dbt_args,
# )


# Set task dependencies if you have more tasks
    load_polygon_data_task >> load_treasury_data_task >> dbt_build_weekly_metrics_task

elt_dag()    



